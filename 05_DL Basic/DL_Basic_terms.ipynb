{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 : DL Basic Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 : Introduction\n",
    "- Implementation skills (tools)\n",
    "    - tensorflow\n",
    "    - pytorch\n",
    "- Math skills\n",
    "    - Linear Algrebra (선형대수학)\n",
    "    - Probability (확률론)\n",
    "- Knowing a lot of recent PAPERS (최신논문경향)\n",
    "    - 14 ~ 15 기본 논문내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 : Contents\n",
    "- 방향성\n",
    "    - 각 주제의 간략한 설명\n",
    "    - 해당 주제의 논문들을 찾아가는 방법\n",
    "- 주제들\n",
    "    1. Historycal Review\n",
    "    2. Neural Network & Multi-Layer Perceptron\n",
    "    3. Optimization Methods\n",
    "    4. Convolutional Neural Networks\n",
    "    5. Modern CNN\n",
    "    6. Compoter Vsion Applications\n",
    "    7. Recurrent Neural Network\n",
    "    8. Transfomer\n",
    "    9. Generative Models Part-1\n",
    "    10. Generative Models Part-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 : 인공지능 분류\n",
    "- Altificial Inteligence (AI) (인공지능) : 인간의 지능을 모방하는 것\n",
    "    - Machine Learing (ML) (기계학습) : 데이터 중심 접근법 \n",
    "        - Deep Learing (DL) (딥러닝) : 인공 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 : Deep Learing Key Conmponents\n",
    "- 새로운 논문과 연구를 바라볼떄 이 네가지를 기준으로 바라보자\n",
    "    - The *Data* that the model can learn from : \n",
    "    - The *Model* how to transfrom the data :\n",
    "    - The *Loss* function that quantifies the badness of the model :\n",
    "    - The *Algorithm* to adjust the parameters to minimize the loss :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 - 01 : DATA\n",
    "- Data depend on the type of the problem to slove\n",
    "    - Classification\n",
    "    - Semantic Segmentation : 각 이미지의 픽셀별로 분류하는것\n",
    "    - Detection : 이미안의 물체의 바운딩 박스를 찾는것\n",
    "    - Pose Estimation : 이지안의 사람의 2,3차원 스켈레톤 정도를 찾는것\n",
    "    - Visual QnA : 질문에 대한 답을 찾는것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 - 02 : Model\n",
    "- 이미지, 단어, 텍스트 등을 원하는 형태의 Label로 바꿔주는 도구\n",
    "    - 모델의 성징에 따라서 결과가 달라지고 그 안에 다양한 테크닉이 있음\n",
    "        - EX\n",
    "            - Alex, GoogLeNet, ResNet, DenseNet, LSTM, Deep AutoEncoders, GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 - 03 : Loss function\n",
    "- 이루고자 하는것의 근사치\n",
    "- 모델과 데이터가 절해져있을때 이 모델을 어떻게 학습할지 여부\n",
    "- 해당 loss Function 을 통상적이라는 이유로 무작정 사용하는것이 아닌 사용되는 이유와 필요시 다른 loss Function 을 적용할 수 있어야 한다\n",
    "\n",
    "    - Loss Function EX\n",
    "        - Regression Task\n",
    "            - MSE (Mean Square Error) = $\\displaystyle{\\frac{1}{N}\\sum_{i=1}^{n}\\sum_{d=1}^{D}({y_i}^{(d)}-{\\hat{y}_i}^{(d)})^2}$\n",
    "        - Classification Task\n",
    "            - CE (CrossEntropy Error) = $\\displaystyle{-\\frac{1}{N}\\sum_{i=1}^{n}\\sum_{d=1}^{D}{y_i}^{(d)}\\log{\\hat{y}_i}^{(d)}}$\n",
    "        - Probabilistic Task\n",
    "            - MLE (Maximum Likelihood Estimation) = $\\displaystyle{\\frac{1}{N}\\sum_{i=1}^{n}\\sum_{d=1}^{D}\\log{\\Nu{}({y_i}^{(d)}\\\\;{\\hat{y}_i}^{(d)},1)} \\quad}$ (=MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 - 04 : optimization Algorithm (최적화 방법)\n",
    "- 데이터, 모델, loss func 가 주어져있을때 네트워크를 어떻게 줄일지 고민하는 것\n",
    "- 또한 한번도 보지못한 테스트 데이터에서도 잘 동작할 수 있도록 하는 것\n",
    "\n",
    "    - EX (오버피팅 방지)\n",
    "        - Dropout\n",
    "        - Early stopping\n",
    "        - K-fold validation\n",
    "        - Weight decay\n",
    "        - Batch normalization\n",
    "        - Mixup\n",
    "        - Ensemble\n",
    "        - Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 : Historical DL Trand Review\n",
    "- 2012 - AlexNet\n",
    "- 2013 - DQN\n",
    "- 2014 - Encoder / Decoder / Adam\n",
    "- 2015 - GAN, ResNet(Residual Network)\n",
    "- 2016 - \n",
    "- 2017 - Transformer\n",
    "- 2018 - Bert\n",
    "- 2019 - Big Language Model (GPT-X)\n",
    "- 2020 - Self Supervised Learning (SimCLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
